// ============================================
// chronelia. - INTEGRACI√ìN CON OPENAI
// ============================================

import { VERCEL_URL } from '@/config/vercel'

const OPENAI_API_KEY = import.meta.env.VITE_OPENAI_API_KEY || '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'
const OPENAI_MODEL = import.meta.env.VITE_OPENAI_MODEL || 'gpt-4o-mini'
const OPENAI_API_URL = 'https://api.openai.com/v1/chat/completions'

// Verificar si OpenAI est√° configurado
export const isOpenAIConfigured = () => {
  return Boolean(OPENAI_API_KEY && OPENAI_API_KEY !== 'sk-your-api-key-here')
}

/**
 * Genera un contexto estructurado con las estad√≠sticas actuales
 * @param {Object} store - Store de Zustand con todos los datos
 * @returns {string} Contexto formateado para la IA
 */
export function generateContext(store) {
  // Validar que store existe y tiene las propiedades necesarias
  if (!store) {
    console.warn('‚ö†Ô∏è Store is undefined')
    return 'Eres un asistente IA especializado en el sistema de gesti√≥n "chronelia".'
  }

  // Usar valores por defecto si las propiedades no existen
  const { 
    activeReservations = [], 
    workers = [], 
    dailyStats = [], 
    history = [] 
  } = store

  // Calcular estad√≠sticas en tiempo real
  const totalReservations = history.length
  const activeCount = activeReservations.length
  const activeWorkers = workers.filter(w => w.active).length
  const totalWorkers = workers.length

  // Estad√≠sticas de hoy
  const today = new Date().toISOString().split('T')[0]
  const todayStats = dailyStats.find(s => s.date === today) || {}

  // Duraci√≥n promedio
  const avgDuration = history.length > 0
    ? Math.round(history.reduce((acc, r) => acc + r.duration, 0) / history.length)
    : 0

  // Ingresos totales
  const totalRevenue = dailyStats.reduce((acc, s) => acc + (s.revenue || 0), 0)

  // √öltimas reservas
  const recentReservations = history.length > 0
    ? history.slice(-5).map(r => 
        `${r.clientName} (${r.duration} min)`
      ).join(', ')
    : 'Ninguna'

  return `
Eres un asistente IA especializado en el sistema de gesti√≥n y crecimiento empresarial "chronelia". 

DATOS ACTUALES DEL NEGOCIO:

üìä RESERVAS:
- Total de reservas: ${totalReservations}
- Reservas activas ahora: ${activeCount}
- Reservas hoy: ${todayStats.totalReservations || 0}
- √öltimas 5 reservas: ${recentReservations || 'Ninguna'}

üë• PERSONAL:
- Total de trabajadores: ${totalWorkers}
- Trabajadores activos: ${activeWorkers}
- Trabajadores inactivos: ${totalWorkers - activeWorkers}

‚è±Ô∏è TIEMPOS:
- Duraci√≥n promedio de servicio: ${avgDuration} minutos

üí∞ INGRESOS:
- Ingresos totales: $${totalRevenue.toLocaleString()}
- Ingresos hoy: $${(todayStats.revenue || 0).toLocaleString()}
- Clientes atendidos hoy: ${todayStats.customers || 0}

INSTRUCCIONES:
- Responde en espa√±ol de forma clara y concisa
- Usa emojis apropiados para hacer las respuestas m√°s visuales
- Proporciona datos espec√≠ficos cuando sea relevante
- Si te preguntan sobre estad√≠sticas, usa los datos proporcionados arriba
- Si detectas oportunidades de mejora, menci√≥nalas
- S√© amigable pero profesional
- Formatea las respuestas con saltos de l√≠nea y bullets cuando sea apropiado
- NO inventes datos que no est√°n en el contexto
`.trim()
}

/**
 * Llama a la API de OpenAI para generar una respuesta
 * @param {string} userMessage - Mensaje del usuario
 * @param {Object} store - Store con datos de la app
 * @param {Array} conversationHistory - Historial de la conversaci√≥n
 * @returns {Promise<string>} Respuesta de la IA
 */
export async function generateAIResponse(userMessage, store, conversationHistory = []) {
  // Determinar si estamos en producci√≥n
  const isProduction = typeof window !== 'undefined' && 
                      window.location.hostname !== 'localhost' && 
                      !window.location.hostname.includes('127.0.0.1')
  
  // Solo verificar configuraci√≥n en desarrollo
  if (!isProduction && !isOpenAIConfigured()) {
    return `‚öôÔ∏è **OpenAI no est√° configurado**

Para usar el chat IA con respuestas avanzadas, necesitas:

1. Obtener una API key de OpenAI en https://platform.openai.com/api-keys
2. Agregar la key al archivo \`.env.local\`:
   \`\`\`
   VITE_OPENAI_API_KEY=sk-tu-api-key-aqui
   \`\`\`
3. Reiniciar la aplicaci√≥n

Mientras tanto, puedo responder preguntas b√°sicas usando el sistema local.`
  }

  try {
    console.log('ü§ñ Enviando petici√≥n a OpenAI...')
    
    // Preparar mensajes
    const messages = [
      {
        role: 'system',
        content: generateContext(store)
      },
      ...conversationHistory.slice(-10).map(msg => ({
        role: msg.role,
        content: msg.content
      })),
      {
        role: 'user',
        content: userMessage
      }
    ]

    // Determinar si estamos en producci√≥n o desarrollo
    const isLocalhost = window.location.hostname === 'localhost' || window.location.hostname.includes('127.0.0.1')
    const isCapacitor = window.location.protocol === 'capacitor:' || window.location.protocol === 'ionic:'
    
    // Determinar qu√© API usar
    let apiUrl, headers
    
    if (isLocalhost) {
      // Desarrollo local: llamada directa a OpenAI
      apiUrl = OPENAI_API_URL
      headers = {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${OPENAI_API_KEY}`
      }
      console.log('üì° Usando API: Directa (OpenAI) - Desarrollo local')
    } else if (isCapacitor) {
      // App nativa: usar URL completa de Vercel desde config
      apiUrl = `${VERCEL_URL}/api/chat`
      headers = { 'Content-Type': 'application/json' }
      console.log('üì° Usando API: Serverless Vercel (App Nativa) -', apiUrl)
    } else {
      // Web en producci√≥n: ruta relativa
      apiUrl = '/api/chat'
      headers = { 'Content-Type': 'application/json' }
      console.log('üì° Usando API: Serverless (/api/chat) - Web Producci√≥n')
    }

    // Llamar a la API (serverless en producci√≥n, directa en desarrollo)
    const response = await fetch(apiUrl, {
      method: 'POST',
      headers,
      body: JSON.stringify({
        model: OPENAI_MODEL,
        messages: messages,
        temperature: 0.7,
        max_tokens: 500
      })
    })

    if (!response.ok) {
      const error = await response.json()
      console.error('‚ùå Error de OpenAI:', error)
      
      // Errores espec√≠ficos
      if (response.status === 401) {
        return 'üîë Error: API key inv√°lida. Verifica tu configuraci√≥n en el archivo `.env`'
      }
      if (response.status === 429) {
        return '‚è≥ Has excedido el l√≠mite de peticiones. Intenta de nuevo en unos minutos.'
      }
      if (response.status === 500) {
        return 'üîß OpenAI est√° experimentando problemas. Intenta de nuevo en unos minutos.'
      }
      
      throw new Error(error.error?.message || 'Error desconocido')
    }

    const data = await response.json()
    console.log('üì¶ Datos recibidos de OpenAI:', data)
    
    // Validar estructura de la respuesta
    if (!data || !data.choices || !Array.isArray(data.choices)) {
      console.error('‚ùå Respuesta inv√°lida - no tiene choices:', data)
      throw new Error('Respuesta de OpenAI con formato inv√°lido')
    }

    if (data.choices.length === 0) {
      console.error('‚ùå Respuesta vac√≠a - choices est√° vac√≠o')
      throw new Error('OpenAI no devolvi√≥ ninguna respuesta')
    }

    const aiMessage = data.choices[0]?.message?.content

    if (!aiMessage || typeof aiMessage !== 'string') {
      console.error('‚ùå Mensaje inv√°lido:', data.choices[0])
      throw new Error('No se recibi√≥ contenido v√°lido de OpenAI')
    }

    console.log('‚úÖ Respuesta recibida de OpenAI')
    return aiMessage.trim()

  } catch (error) {
    console.error('üí• Error al llamar a OpenAI:', error)
    
    return `‚ùå **Error al conectar con OpenAI**

${error.message}

**Posibles soluciones:**
‚Ä¢ Verifica tu conexi√≥n a internet
‚Ä¢ Confirma que tu API key es v√°lida
‚Ä¢ Revisa que tienes cr√©ditos disponibles en OpenAI
‚Ä¢ Intenta de nuevo en unos momentos

Mientras tanto, puedo responder preguntas b√°sicas usando el sistema local.`
  }
}

/**
 * Obtiene estad√≠sticas de uso de la API
 * @returns {Object} Informaci√≥n sobre el uso
 */
export function getAPIStatus() {
  return {
    configured: isOpenAIConfigured(),
    model: OPENAI_MODEL,
    hasKey: Boolean(OPENAI_API_KEY)
  }
}

// Debug: Log del estado de configuraci√≥n
console.log('üîß Estado de OpenAI:', {
  configured: isOpenAIConfigured(),
  model: OPENAI_MODEL,
  hasKey: Boolean(OPENAI_API_KEY),
  keyPreview: OPENAI_API_KEY ? `${OPENAI_API_KEY.substring(0, 10)}...` : 'No configurada',
  keyLength: OPENAI_API_KEY ? OPENAI_API_KEY.length : 0,
  envVarRaw: import.meta.env.VITE_OPENAI_API_KEY ? 'Presente en import.meta.env ‚úÖ' : 'NO presente en import.meta.env ‚ùå'
})

